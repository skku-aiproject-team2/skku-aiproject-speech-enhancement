{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터셋 설정\n",
    "\n",
    "**필요한 경우만 실행할 것**\n",
    "\n",
    "dns/datasets/...에 있는 테스트 데이터를 eval_data로 복사한 후,\n",
    "\n",
    "noisy의 데이터들의 이름을 noisy_fileid_12.wav와 같이 변경합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "\n",
    "def copytree(src, dst, symlinks=False, ignore=None):\n",
    "    for item in os.listdir(src):\n",
    "        s = os.path.join(src, item)\n",
    "        d = os.path.join(dst, item)\n",
    "        if os.path.isdir(s):\n",
    "            shutil.copytree(s, d, symlinks, ignore)\n",
    "        else:\n",
    "            shutil.copy2(s, d)\n",
    "\n",
    "\n",
    "original_testset_path = os.path.join(\n",
    "    \"dns\", \"datasets\", \"test_set\", \"synthetic\", \"no_reverb\"\n",
    ")\n",
    "new_testset_path = os.path.join(\"eval_data\")\n",
    "\n",
    "if not os.path.exists(new_testset_path):\n",
    "    os.mkdir(new_testset_path)\n",
    "\n",
    "copytree(original_testset_path, new_testset_path)\n",
    "\n",
    "noisy_files = os.listdir(os.path.join(new_testset_path, \"noisy\"))\n",
    "\n",
    "for file in noisy_files:\n",
    "    m = re.search(r\"_fileid_\\d+.wav\", y)\n",
    "    if m != None:\n",
    "        os.rename(file, \"noisy\" + m.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비교용 템플릿\n",
    "\n",
    "먼저 메트릭을 뽑아내는 부분입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from pesq import pesq\n",
    "from pystoi import stoi\n",
    "\n",
    "\n",
    "def result_to_metric(result):\n",
    "    metric = defaultdict(float)\n",
    "\n",
    "    metric[\"pesq_wb\"] = result[\"pesq_wb\"] / result[\"count\"]\n",
    "    metric[\"pesq_nb\"] = result[\"pesq_nb\"] / result[\"count\"]\n",
    "    metric[\"stoi\"] = result[\"stoi\"] / result[\"count\"]\n",
    "    metric[\"rtf\"] = result[\"infer_time\"] / result[\"length\"]\n",
    "\n",
    "    return metric\n",
    "\n",
    "\n",
    "def eval_metric(infer, target_name, testset_path=\"eval\"):\n",
    "    result = defaultdict(int)\n",
    "\n",
    "    for i in tqdm(range(300)):\n",
    "        duration = 0\n",
    "        try:\n",
    "            rate, clean = wavfile.read(\n",
    "                os.path.join(testset_path, \"clean\", \"clean_fileid_{}.wav\".format(i))\n",
    "            )\n",
    "            # As we infer on the CPU device, we don't need to sync with GPU.\n",
    "            # So, we can utilize time.\n",
    "            start_time = time.time()\n",
    "            rate, target_wav = infer(rate, clean, i)\n",
    "            n_samples = target_wav.shape[-1]\n",
    "            duration = time.time() - start_time\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        n_samples = target_wav.shape[-1]\n",
    "        length = n_samples / rate\n",
    "\n",
    "        result[\"pesq_wb\"] += (\n",
    "            pesq(rate, clean, target_wav, \"wb\") * n_samples\n",
    "        )  # wide band\n",
    "        result[\"pesq_nb\"] += (\n",
    "            pesq(rate, clean, target_wav, \"nb\") * n_samples\n",
    "        )  # narrow band\n",
    "        result[\"stoi\"] += stoi(clean, target_wav, rate) * n_samples\n",
    "        result[\"count\"] += 1 * n_samples\n",
    "        result[\"length\"] += length\n",
    "        result[\"infer_time\"] += duration\n",
    "\n",
    "    if result[\"count\"] is None:\n",
    "        return None\n",
    "    metric = result_to_metric(result)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "infer에 들어갈 spectral_subtraction 함수입니다.\n",
    "\n",
    "메트릭을 구하기 위해 길이가 같아야 해서 코드를 적절히 변경하였습니다.\n",
    "\n",
    "해당 코드를 비교해보시면 변경된 부분을 쉽게 구하실 수 있을 거에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_subtraction(rate: int, clean: NDArray, i: int):\n",
    "    fft = abs(np.fft.fft(clean))\n",
    "    len_ = 20 * rate // 1000  # frame size in samples\n",
    "    PERC = 50  # window overlap in percent of frame\n",
    "    len1 = len_ * PERC // 100  # overlap'length\n",
    "    len2 = len_ - len1  # window'length - overlap'length\n",
    "\n",
    "    # setting default parameters\n",
    "    Thres = 3  # VAD threshold in dB SNRseg\n",
    "    Expnt = 1.0  # exp(Expnt)\n",
    "    G = 0.9\n",
    "\n",
    "    # initial Hamming window\n",
    "    win = np.hamming(len_)\n",
    "    # normalization gain for overlap+add with 50% overlap\n",
    "    winGain = len2 / sum(win)\n",
    "\n",
    "    # nFFT = 2 * 2 ** (nextpow2.nextpow2(len_))\n",
    "    nFFT = 2 * 2**8\n",
    "    noise_mean = np.zeros(nFFT)\n",
    "    j = 1\n",
    "    for k in range(1, 6):\n",
    "        noise_mean = noise_mean + abs(np.fft.fft(win * clean[j : j + len_], nFFT))\n",
    "        j = j + len_\n",
    "    noise_mu = noise_mean / 5\n",
    "\n",
    "    # initialize various variables\n",
    "    k = 1\n",
    "    img = 1j\n",
    "    x_old = np.zeros(len1)\n",
    "    Nframes = len(clean) // len2 - 1\n",
    "    xfinal = np.zeros((Nframes + 1) * len2)\n",
    "\n",
    "    # === Start Processing === #\n",
    "    for n in range(0, Nframes):\n",
    "        # Windowing\n",
    "        insign = win * clean[k - 1 : k + len_ - 1]\n",
    "        # compute fourier transform of a frame\n",
    "        spec = np.fft.fft(insign, nFFT)\n",
    "        # compute the magnitude\n",
    "        sig = abs(spec)\n",
    "        # save the noisy phase information\n",
    "        theta = np.angle(spec)\n",
    "        # SNR\n",
    "        SNRseg = 10 * np.log10(\n",
    "            np.linalg.norm(sig, 2) ** 2 / np.linalg.norm(noise_mu, 2) ** 2\n",
    "        )\n",
    "\n",
    "        # --- spectral subtraction --- #\n",
    "        sub_speech = sig**Expnt - noise_mu**Expnt\n",
    "        # the pure signal is less than the noise signal power\n",
    "        diffw = sig**Expnt - noise_mu**Expnt\n",
    "\n",
    "        # beta negative components\n",
    "        def find_index(x_list):\n",
    "            index_list = []\n",
    "            for i in range(len(x_list)):\n",
    "                if x_list[i] < 0:\n",
    "                    index_list.append(i)\n",
    "            return index_list\n",
    "\n",
    "        z = find_index(diffw)\n",
    "        if len(z) > 0:\n",
    "            sub_speech[z] = 0\n",
    "\n",
    "        # --- implement a simple VAD detector --- #\n",
    "        if SNRseg < Thres:  # Update noise spectrum\n",
    "            noise_temp = (\n",
    "                G * noise_mu**Expnt + (1 - G) * sig**Expnt\n",
    "            )  # Smoothing processing noise power spectrum\n",
    "            noise_mu = noise_temp ** (1 / Expnt)  # New noise amplitude spectrum\n",
    "\n",
    "        # add phase\n",
    "        x_phase = (sub_speech ** (1 / Expnt)) * np.exp(img * theta)\n",
    "        # take the IFFT\n",
    "        xi = np.fft.ifft(x_phase).real\n",
    "\n",
    "        # --- Overlap and add --- #\n",
    "        xfinal[k - 1 : k + len2 - 1] = x_old + xi[0:len1]\n",
    "        x_old = xi[0 + len1 : len_]\n",
    "\n",
    "        k = k + len2\n",
    "\n",
    "    xfinal[k - 1 : k + len2 - 1] = x_old\n",
    "\n",
    "    return rate, winGain * xfinal.astype(clean.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에 새로운 infer 함수를 만들어주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메트릭을 측정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:09<00:00,  4.29it/s]\n",
      "100%|██████████| 300/300 [01:34<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'noisy': defaultdict(<class 'float'>, {'pesq_wb': 1.5853275564692964, 'pesq_nb': 2.1636971763316417, 'stoi': 0.9156399918415755, 'rtf': 5.7368310505911805e-05}), 'spectral_subtraction': defaultdict(<class 'float'>, {'pesq_wb': 4.105553290987975, 'pesq_nb': 4.255975185624705, 'stoi': 0.9969548738942908, 'rtf': 0.01921462676669127})}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "testset_path = \"eval_data\"\n",
    "\n",
    "\n",
    "def load_noisy(_rate, _clean, i):\n",
    "    return wavfile.read(os.path.join(testset_path, \"noisy\", \"noisy_fileid_{}.wav\".format(i)))\n",
    "\n",
    "\n",
    "targets = [\n",
    "    {\"name\": \"noisy\", \"infer\": load_noisy},\n",
    "    {\"name\": \"spectral_subtraction\", \"infer\": spectral_subtraction},\n",
    "]\n",
    "\n",
    "metrics = {}\n",
    "for target in targets:\n",
    "    metric = eval_metric(target[\"infer\"], target[\"name\"], testset_path)\n",
    "    metrics[target[\"name\"]] = metric\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics를 표, 그래프 등으로 시각화합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 주어진 데이터\n",
    "\n",
    "    \n",
    "\n",
    "# x 축 레이블\n",
    "labels = ['pesq_nb', 'pesq_wb', 'rtf', 'stoi']\n",
    "\n",
    "# 각 방법의 데이터를 리스트로 정리\n",
    "noisy_data = [metrics['noisy'][label] for label in labels]\n",
    "spectral_data = [metrics['spectral_subtraction'][label] for label in labels]\n",
    "mmse_data = [metrics['mmse'][label] for label in labels]\n",
    "wiener_data = [metrics['wiener_filtering'][label] for label in labels]\n",
    "\n",
    "# 막대의 위치\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "# 막대의 너비\n",
    "width = 0.2\n",
    "\n",
    "# 플롯 생성\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# 각 데이터 방법에 대한 막대 그래프\n",
    "rects1 = ax.bar(x - 1.5*width, noisy_data, width, label='noisy')\n",
    "rects2 = ax.bar(x - 0.5*width, spectral_data, width, label='spectral_subtraction')\n",
    "rects3 = ax.bar(x + 0.5*width, mmse_data, width, label='mmse')\n",
    "rects4 = ax.bar(x + 1.5*width, wiener_data, width, label='wiener_filtering')\n",
    "\n",
    "# x축 레이블 설정\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('Comparison of Different Denoising Methods')\n",
    "ax.legend()\n",
    "\n",
    "# 막대 위에 값 표시\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "\n",
    "# 레이아웃 조정\n",
    "fig.tight_layout()\n",
    "\n",
    "# 그래프 표시\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
