{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비교용 템플릿\n",
    "\n",
    "먼저 메트릭을 뽑아내는 부분입니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "import traceback\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from pesq import pesq\n",
    "from pystoi import stoi\n",
    "\n",
    "from pathlib import Path\n",
    "import wave\n",
    "\n",
    "\n",
    "def prettier(obj):\n",
    "    print(json.dumps(obj, indent=4, sort_keys=True))\n",
    "\n",
    "\n",
    "def next_power_of_2(x):\n",
    "    return 1 if x == 0 else 2 ** (x - 1).bit_length()\n",
    "\n",
    "\n",
    "def result_to_metric(result):\n",
    "    metric = defaultdict(float)\n",
    "\n",
    "    prettier(result)\n",
    "    metric[\"pesq_wb\"] = result[\"pesq_wb\"] / result[\"count\"]\n",
    "    metric[\"pesq_nb\"] = result[\"pesq_nb\"] / result[\"count\"]\n",
    "    metric[\"stoi\"] = result[\"stoi\"] / result[\"count\"]\n",
    "    metric[\"rtf\"] = result[\"infer_time\"] / result[\"length\"]\n",
    "\n",
    "    return metric\n",
    "\n",
    "\n",
    "def save_enhanced_audio(rate, enhanced_audio, output_dir, filename):\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Convert floating point audio to int16\n",
    "    if enhanced_audio.dtype != np.int16:\n",
    "        enhanced_audio = np.int16(\n",
    "            enhanced_audio / np.max(np.abs(enhanced_audio)) * 32767\n",
    "        )\n",
    "\n",
    "    # Save the enhanced audio using wave module\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    wf = wave.open(output_path, \"wb\")\n",
    "    wf.setnchannels(1)  # Assuming mono audio\n",
    "    wf.setsampwidth(2)  # Assuming 16-bit audio\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(enhanced_audio.tostring())\n",
    "    wf.close()\n",
    "\n",
    "\n",
    "def eval_metric(\n",
    "    infer, target_name, testset_path, load: bool, output_base_dir=\"enhanced_output\"\n",
    "):\n",
    "    result = defaultdict(int)\n",
    "\n",
    "    cleans = os.listdir(os.path.join(testset_path, \"clean\"))\n",
    "    # noises = os.listdir(os.path.join(testset_path, \"noisy\"))\n",
    "\n",
    "    output_dir = os.path.join(output_base_dir, target_name)\n",
    "\n",
    "    for i in tqdm(range(len(cleans))):\n",
    "        duration = 0\n",
    "        try:\n",
    "            rate, clean = wavfile.read(os.path.join(testset_path, \"clean\", cleans[i]))\n",
    "            rate, noisy = wavfile.read(os.path.join(testset_path, \"noisy\", cleans[i]))\n",
    "            if load:\n",
    "                rate, target_wav = wavfile.read(\n",
    "                    os.path.join(testset_path, target_name, cleans[i])\n",
    "                )\n",
    "            else:\n",
    "                # As we infer on the CPU device, we don't need to sync with GPU.\n",
    "                # So, we can utilize time.\n",
    "                start_time = time.time()\n",
    "                rate, target_wav = infer(rate, noisy, i)\n",
    "                duration = time.time() - start_time\n",
    "\n",
    "            # Save the enhanced audio\n",
    "            save_enhanced_audio(rate, target_wav, output_dir, cleans[i])\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            return\n",
    "            continue\n",
    "\n",
    "        n_samples = target_wav.shape[-1]\n",
    "        length = n_samples / rate\n",
    "\n",
    "        result[\"pesq_wb\"] += (\n",
    "            pesq(16000, clean, target_wav, \"wb\") * n_samples\n",
    "        )  # wide band\n",
    "        result[\"pesq_nb\"] += (\n",
    "            pesq(16000, clean, target_wav, \"nb\") * n_samples\n",
    "        )  # narrow band\n",
    "        result[\"stoi\"] += stoi(clean, target_wav, rate) * n_samples\n",
    "        result[\"count\"] += 1 * n_samples\n",
    "        result[\"length\"] += length\n",
    "        result[\"infer_time\"] += duration\n",
    "\n",
    "    if result[\"count\"] is None:\n",
    "        return None\n",
    "    metric = result_to_metric(result)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "infer에 들어갈 spectral_subtraction 함수입니다.\n",
    "\n",
    "메트릭을 구하기 위해 길이가 같아야 해서 코드를 적절히 변경하였습니다.\n",
    "\n",
    "해당 코드를 비교해보시면 변경된 부분을 쉽게 구하실 수 있을 거에요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def spectral_subtraction(rate: int, noisy: NDArray, target_name: str):\n",
    "    fft = abs(np.fft.fft(noisy))\n",
    "    len_ = 20 * rate // 1000  # frame size in samples\n",
    "    PERC = 50  # window overlap in percent of frame\n",
    "    len1 = len_ * PERC // 100  # overlap'length\n",
    "    len2 = len_ - len1  # window'length - overlap'length\n",
    "\n",
    "    # setting default parameters\n",
    "    Thres = 3  # VAD threshold in dB SNRseg\n",
    "    Expnt = 1.0  # exp(Expnt)\n",
    "    G = 0.9\n",
    "\n",
    "    # initial Hamming window\n",
    "    win = np.hamming(len_)\n",
    "    # normalization gain for overlap+add with 50% overlap\n",
    "    winGain = len2 / sum(win)\n",
    "\n",
    "    # nFFT = 2 * 2 ** (nextpow2.nextpow2(len_))\n",
    "    nFFT = 2 * next_power_of_2(len_)\n",
    "    noise_mean = np.zeros(nFFT)\n",
    "    j = 1\n",
    "    for k in range(1, 6):\n",
    "        noise_mean = noise_mean + abs(np.fft.fft(win * noisy[j : j + len_], nFFT))\n",
    "        j = j + len_\n",
    "    noise_mu = noise_mean / 5\n",
    "\n",
    "    # initialize various variables\n",
    "    k = 1\n",
    "    img = 1j\n",
    "    x_old = np.zeros(len1)\n",
    "    Nframes = len(noisy) // len2 - 1\n",
    "    xfinal = np.zeros(noisy.shape[0])\n",
    "\n",
    "    # === Start Processing === #\n",
    "    for n in range(0, Nframes):\n",
    "        # Windowing\n",
    "        insign = win * noisy[k - 1 : k + len_ - 1]\n",
    "        # compute fourier transform of a frame\n",
    "        spec = np.fft.fft(insign, nFFT)\n",
    "        # compute the magnitude\n",
    "        sig = abs(spec)\n",
    "        # save the noisy phase information\n",
    "        theta = np.angle(spec)\n",
    "        # SNR\n",
    "        SNRseg = 10 * np.log10(\n",
    "            np.linalg.norm(sig, 2) ** 2 / np.linalg.norm(noise_mu, 2) ** 2\n",
    "        )\n",
    "\n",
    "        # --- spectral subtraction --- #\n",
    "        sub_speech = sig**Expnt - noise_mu**Expnt\n",
    "        # the pure signal is less than the noise signal power\n",
    "        diffw = sig**Expnt - noise_mu**Expnt\n",
    "\n",
    "        # beta negative components\n",
    "        def find_index(x_list):\n",
    "            index_list = []\n",
    "            for i in range(len(x_list)):\n",
    "                if x_list[i] < 0:\n",
    "                    index_list.append(i)\n",
    "            return index_list\n",
    "\n",
    "        z = find_index(diffw)\n",
    "        if len(z) > 0:\n",
    "            sub_speech[z] = 0\n",
    "\n",
    "        # --- implement a simple VAD detector --- #\n",
    "        if SNRseg < Thres:  # Update noise spectrum\n",
    "            noise_temp = (\n",
    "                G * noise_mu**Expnt + (1 - G) * sig**Expnt\n",
    "            )  # Smoothing processing noise power spectrum\n",
    "            noise_mu = noise_temp ** (1 / Expnt)  # New noise amplitude spectrum\n",
    "\n",
    "        # add phase\n",
    "        x_phase = (sub_speech ** (1 / Expnt)) * np.exp(img * theta)\n",
    "        # take the IFFT\n",
    "        xi = np.fft.ifft(x_phase).real\n",
    "\n",
    "        # --- Overlap and add --- #\n",
    "        xfinal[k - 1 : k + len2 - 1] = x_old + xi[0:len1]\n",
    "        x_old = xi[0 + len1 : len_]\n",
    "\n",
    "        k = k + len2\n",
    "\n",
    "    xfinal[k - 1 : k + len2 - 1] = x_old\n",
    "\n",
    "    return rate, winGain * xfinal.astype(noisy.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "infer에 들어갈 MMSE 함수입니다.\n",
    "\n",
    "메트릭을 구하기 위해 길이가 같아야 해서 코드를 적절히 변경하였습니다.\n",
    "\n",
    "해당 코드를 비교해보시면 변경된 부분을 쉽게 구하실 수 있을 거에요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special as sp\n",
    "\n",
    "\n",
    "def mmse(rate: int, noisy: NDArray, i: int):\n",
    "    len_ = 20 * rate // 1000  # frame size in samples\n",
    "    PERC = 50  # window overlap in percent of frame\n",
    "    len1 = len_ * PERC // 100  # overlap'length\n",
    "    len2 = len_ - len1  # window'length - overlop'length\n",
    "\n",
    "    # setting default parameters\n",
    "    aa = 0.98\n",
    "    eta = 0.15\n",
    "    Thres = 3\n",
    "    mu = 0.98\n",
    "    c = np.sqrt(np.pi) / 2\n",
    "    ksi_min = 10 ** (-25 / 10)\n",
    "\n",
    "    # hamming window\n",
    "    win = np.hamming(len_)\n",
    "    # normalization gain for overlap+add with 50% overlap\n",
    "    winGain = len2 / sum(win)\n",
    "\n",
    "    # setting initial noise\n",
    "    nFFT = 2 * next_power_of_2(len_)\n",
    "    j = 1\n",
    "    noise_mean = np.zeros(nFFT)\n",
    "    for k in range(1, 6):\n",
    "        noise_mean = noise_mean + abs(np.fft.fft(win * noisy[j : j + len_], nFFT))\n",
    "        j = j + len_\n",
    "    noise_mu = noise_mean / 5\n",
    "    noise_mu2 = noise_mu**2\n",
    "\n",
    "    # initialize various variables\n",
    "    k = 1\n",
    "    img = 1j\n",
    "    x_old = np.zeros(len2)\n",
    "    Nframes = len(noisy) // len2 - 1\n",
    "    xfinal = np.zeros(Nframes * len2)\n",
    "\n",
    "    # === Start Processing ==== #\n",
    "    for n in range(0, Nframes):\n",
    "\n",
    "        # Windowing\n",
    "        insign = win * noisy[k - 1 : k + len_ - 1]\n",
    "\n",
    "        # Take fourier transform of frame\n",
    "        spec = np.fft.fft(insign, nFFT)\n",
    "        sig = abs(spec)\n",
    "        sig2 = sig**2\n",
    "        # save the noisy phase information\n",
    "        theta = np.angle(spec)\n",
    "\n",
    "        SNRpos = 10 * np.log10(\n",
    "            np.linalg.norm(sig, 2) ** 2 / np.linalg.norm(noise_mu, 2) ** 2\n",
    "        )\n",
    "\n",
    "        # posteriori SNR\n",
    "        gammak = np.minimum(sig2 / noise_mu2, 40)\n",
    "\n",
    "        # decision-direct estimate of a priori SNR  P231 [7.75]\n",
    "        if n == 0:\n",
    "            ksi = aa + (1 - aa) * np.maximum(gammak - 1, 0)\n",
    "        else:\n",
    "            ksi = aa * Xk_prev / noise_mu2 + (1 - aa) * np.maximum(gammak - 1, 0)\n",
    "            # limit ksi to -25 dB\n",
    "            ksi = np.maximum(ksi_min, ksi)\n",
    "\n",
    "        # --- implement a simple VAD detector --- #\n",
    "        if SNRpos < Thres:  # Update noise spectrum\n",
    "            noise_mu2 = (\n",
    "                mu * noise_mu2 + (1 - mu) * sig2\n",
    "            )  # Smoothing processing noise power spectrum\n",
    "            noise_mu = np.sqrt(noise_mu2)\n",
    "\n",
    "        # [7.40]\n",
    "        vk = gammak * ksi / (1 + ksi)\n",
    "        j_0 = sp.iv(\n",
    "            0, vk / 2\n",
    "        )  # modified bessel function of the first kind of real order\n",
    "        j_1 = sp.iv(1, vk / 2)\n",
    "        C = np.exp(-0.5 * vk)\n",
    "        A = ((c * (vk**0.5)) * C) / gammak  # [7.40] A\n",
    "        B = (1 + vk) * j_0 + vk * j_1  # [7.40] B\n",
    "        hw = A * B  # [7.40]\n",
    "\n",
    "        # get X(w)\n",
    "        mmse_speech = hw * sig\n",
    "\n",
    "        # save for estimation of a priori SNR in next frame\n",
    "        Xk_prev = mmse_speech**2\n",
    "\n",
    "        # IFFT\n",
    "        x_phase = mmse_speech * np.exp(img * theta)\n",
    "        xi_w = np.fft.ifft(x_phase, nFFT).real\n",
    "\n",
    "        # overlap add\n",
    "        xfinal[k - 1 : k + len2 - 1] = x_old + xi_w[0:len1]\n",
    "        x_old = xi_w[len1 + 0 : len_]\n",
    "\n",
    "        k = k + len2\n",
    "\n",
    "    xfinal = winGain * xfinal.astype(noisy.dtype)\n",
    "\n",
    "    # Overlap으로 인해 크기 차이 발생\n",
    "    if len(xfinal) < len(noisy):\n",
    "        xfinal = np.pad(xfinal, (0, len(noisy) - len(xfinal)), \"constant\")\n",
    "    else:\n",
    "        xfinal = xfinal[: len(noisy)]\n",
    "\n",
    "    return rate, xfinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "infer에 들어갈 Wiener Filtering 함수입니다.\n",
    "\n",
    "메트릭을 구하기 위해 길이가 같아야 해서 코드를 적절히 변경하였습니다.\n",
    "\n",
    "해당 코드를 비교해보시면 변경된 부분을 쉽게 구하실 수 있을 거에요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiener_filtering(rate: int, noisy: NDArray, i: int):\n",
    "    len_ = 20 * rate // 1000  # frame size in samples\n",
    "    PERC = 50  # window overlap in percent of frame\n",
    "    len1 = len_ * PERC // 100  # overlap'length\n",
    "    len2 = len_ - len1  # window'length - overlop'length\n",
    "\n",
    "    # setting default parameters\n",
    "    Thres = 3  # VAD threshold in dB SNRseg\n",
    "    Expnt = 1.0\n",
    "    G = 0.9\n",
    "\n",
    "    # sine window\n",
    "    i = np.linspace(0, len_ - 1, len_)\n",
    "    win = np.sqrt(2 / (len_ + 1)) * np.sin(np.pi * (i + 1) / (len_ + 1))\n",
    "\n",
    "    # normalization gain for overlap+add with 50% overlap\n",
    "    winGain = len2 / sum(win)\n",
    "\n",
    "    # setting initial noise\n",
    "    nFFT = 2 * next_power_of_2(len_)\n",
    "    j = 1\n",
    "    noise_mean = np.zeros(nFFT)\n",
    "    for k in range(1, 6):\n",
    "        noise_mean = noise_mean + abs(np.fft.fft(win * noisy[j : j + len_], nFFT))\n",
    "        j = j + len_\n",
    "    noise_mu = noise_mean / 5\n",
    "\n",
    "    # initialize various variables\n",
    "    k = 1\n",
    "    img = 1j\n",
    "    x_old = np.zeros(len1)\n",
    "    Nframes = len(noisy) // len2 - 1\n",
    "    xfinal = np.zeros(Nframes * len2)\n",
    "\n",
    "    # === Start Processing ==== #\n",
    "    for n in range(0, Nframes):\n",
    "\n",
    "        # Windowing\n",
    "        insign = win * noisy[k - 1 : k + len_ - 1]\n",
    "        # compute fourier transform of a frame\n",
    "        spec = np.fft.fft(insign, nFFT)\n",
    "        # compute the magnitude\n",
    "        sig = abs(spec)\n",
    "        # save the noisy phase information\n",
    "        theta = np.angle(spec)\n",
    "        # Posterior SNR\n",
    "        SNRpos = 10 * np.log10(\n",
    "            np.linalg.norm(sig, 2) ** 2 / np.linalg.norm(noise_mu, 2) ** 2\n",
    "        )\n",
    "\n",
    "        # --- wiener filtering --- #\n",
    "        sub_speech = sig**Expnt - noise_mu**Expnt\n",
    "        diffw = sig**Expnt - noise_mu**Expnt\n",
    "\n",
    "        def find_index(x_list):\n",
    "            index_list = []\n",
    "            for i in range(len(x_list)):\n",
    "                if x_list[i] < 0:\n",
    "                    index_list.append(i)\n",
    "            return index_list\n",
    "\n",
    "        z = find_index(diffw)\n",
    "        if len(z) > 0:\n",
    "            sub_speech[z] = 0\n",
    "\n",
    "        SNRpri = 10 * np.log10(\n",
    "            np.linalg.norm(sub_speech, 2) ** 2 / np.linalg.norm(noise_mu, 2) ** 2\n",
    "        )\n",
    "        mel_max = 10\n",
    "        mel_0 = (1 + 4 * mel_max) / 5\n",
    "        s = 25 / (mel_max - 1)\n",
    "\n",
    "        def get_mel(SNR):\n",
    "            if -5.0 <= SNR <= 20.0:\n",
    "                a = mel_0 - SNR / s\n",
    "            else:\n",
    "                if SNR < -5.0:\n",
    "                    a = mel_max\n",
    "                if SNR > 20:\n",
    "                    a = 1\n",
    "            return a\n",
    "\n",
    "        mel = get_mel(SNRpri)\n",
    "        G_k = sub_speech**2 / (sub_speech**2 + mel * noise_mu**2)\n",
    "        wf_speech = G_k * sig\n",
    "\n",
    "        if SNRpos < Thres:\n",
    "            noise_temp = G * noise_mu**Expnt + (1 - G) * sig**Expnt\n",
    "            noise_mu = noise_temp ** (1 / Expnt)\n",
    "\n",
    "        x_phase = wf_speech * np.exp(img * theta)\n",
    "        xi = np.fft.ifft(x_phase).real\n",
    "\n",
    "        xfinal[k - 1 : k + len2 - 1] = x_old + xi[0:len1]\n",
    "        x_old = xi[0 + len1 : len_]\n",
    "\n",
    "        k = k + len2\n",
    "\n",
    "    xfinal = winGain * xfinal.astype(noisy.dtype)\n",
    "\n",
    "    # Overlap으로 인해 크기 차이 발생\n",
    "    if len(xfinal) < len(noisy):\n",
    "        xfinal = np.pad(xfinal, (0, len(noisy) - len(xfinal)), \"constant\")\n",
    "    else:\n",
    "        xfinal = xfinal[: len(noisy)]\n",
    "\n",
    "    return rate, xfinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메트릭을 측정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 412/412 [01:29<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"count\": 49972070,\n",
      "    \"infer_time\": 0,\n",
      "    \"length\": 1041.0847916666664,\n",
      "    \"pesq_nb\": 128521217.5592233,\n",
      "    \"pesq_wb\": 97583204.8157301,\n",
      "    \"stoi\": 46353905.54622736\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 412/412 [02:02<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"count\": 49972070,\n",
      "    \"infer_time\": 42.98717904090881,\n",
      "    \"length\": 1041.0847916666664,\n",
      "    \"pesq_nb\": 138189005.7308668,\n",
      "    \"pesq_wb\": 107150051.56963086,\n",
      "    \"stoi\": 46188702.048720405\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 412/412 [02:25<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"count\": 49972070,\n",
      "    \"infer_time\": 64.70135641098022,\n",
      "    \"length\": 1041.0847916666664,\n",
      "    \"pesq_nb\": 130781402.69985962,\n",
      "    \"pesq_wb\": 99690655.95318425,\n",
      "    \"stoi\": 44975654.26802755\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 412/412 [02:01<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"count\": 49972070,\n",
      "    \"infer_time\": 41.88861417770386,\n",
      "    \"length\": 1041.0847916666664,\n",
      "    \"pesq_nb\": 130986113.251472,\n",
      "    \"pesq_wb\": 97041702.95830762,\n",
      "    \"stoi\": 45550615.41517785\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 412/412 [01:26<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"count\": 49972070,\n",
      "    \"infer_time\": 0,\n",
      "    \"length\": 1041.0847916666664,\n",
      "    \"pesq_nb\": 132173382.18717277,\n",
      "    \"pesq_wb\": 102458708.39949071,\n",
      "    \"stoi\": 46712186.653452545\n",
      "}\n",
      "{\n",
      "    \"baseline\": {\n",
      "        \"pesq_nb\": 2.644945110081947,\n",
      "        \"pesq_wb\": 2.050319476449359,\n",
      "        \"rtf\": 0,\n",
      "        \"stoi\": 0.9347658932970466\n",
      "    },\n",
      "    \"mmse\": {\n",
      "        \"pesq_nb\": 2.6170899604490994,\n",
      "        \"pesq_wb\": 1.994927485557117,\n",
      "        \"rtf\": 0.06214801803741673,\n",
      "        \"stoi\": 0.9000158342055382\n",
      "    },\n",
      "    \"noisy\": {\n",
      "        \"pesq_nb\": 2.5718609927350076,\n",
      "        \"pesq_wb\": 1.9527549052046491,\n",
      "        \"rtf\": 0,\n",
      "        \"stoi\": 0.9275962661988458\n",
      "    },\n",
      "    \"spectral_subtraction\": {\n",
      "        \"pesq_nb\": 2.7653248250646167,\n",
      "        \"pesq_wb\": 2.14419878083159,\n",
      "        \"rtf\": 0.041290756896074615,\n",
      "        \"stoi\": 0.9242903495636744\n",
      "    },\n",
      "    \"wiener_filtering\": {\n",
      "        \"pesq_nb\": 2.6211864597858763,\n",
      "        \"pesq_wb\": 1.9419188150162205,\n",
      "        \"rtf\": 0.04023554518613669,\n",
      "        \"stoi\": 0.9115214842046337\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "testset_path = \"dataset/test\"\n",
    "\n",
    "\n",
    "def noisy(_rate, noisy, i):\n",
    "    return _rate, noisy\n",
    "\n",
    "\n",
    "targets = [\n",
    "    {\"name\": \"noisy\", \"infer\": noisy, \"rtf\": 0, \"load\": True},\n",
    "    {\n",
    "        \"name\": \"spectral_subtraction\",\n",
    "        \"infer\": spectral_subtraction,\n",
    "        \"rtf\": None,\n",
    "        \"load\": False,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"mmse\",\n",
    "        \"infer\": mmse,\n",
    "        \"rtf\": None,\n",
    "        \"load\": False,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"wiener_filtering\",\n",
    "        \"infer\": wiener_filtering,\n",
    "        \"rtf\": None,\n",
    "        \"load\": False,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"baseline\",\n",
    "        \"infer\": None,\n",
    "        \"rtf\": 0,\n",
    "        \"load\": True,\n",
    "    },\n",
    "]\n",
    "\n",
    "metrics = {}\n",
    "for target in targets:\n",
    "    metric = eval_metric(target[\"infer\"], target[\"name\"], testset_path, target[\"load\"])\n",
    "    if target[\"rtf\"] is not None:\n",
    "        metric[\"rtf\"] = target[\"rtf\"]\n",
    "    metrics[target[\"name\"]] = metric\n",
    "prettier(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics를 표, 그래프 등으로 시각화합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 주어진 데이터\n",
    "\n",
    "    \n",
    "\n",
    "# x 축 레이블\n",
    "labels = ['pesq_nb', 'pesq_wb', 'rtf', 'stoi']\n",
    "\n",
    "# 각 방법의 데이터를 리스트로 정리\n",
    "noisy_data = [metrics['noisy'][label] for label in labels]\n",
    "spectral_data = [metrics['spectral_subtraction'][label] for label in labels]\n",
    "mmse_data = [metrics['mmse'][label] for label in labels]\n",
    "wiener_data = [metrics['wiener_filtering'][label] for label in labels]\n",
    "\n",
    "# 막대의 위치\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "# 막대의 너비\n",
    "width = 0.2\n",
    "\n",
    "# 플롯 생성\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# 각 데이터 방법에 대한 막대 그래프\n",
    "rects1 = ax.bar(x - 1.5*width, noisy_data, width, label='noisy')\n",
    "rects2 = ax.bar(x - 0.5*width, spectral_data, width, label='spectral_subtraction')\n",
    "rects3 = ax.bar(x + 0.5*width, mmse_data, width, label='mmse')\n",
    "rects4 = ax.bar(x + 1.5*width, wiener_data, width, label='wiener_filtering')\n",
    "\n",
    "# x축 레이블 설정\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('Comparison of Different Denoising Methods')\n",
    "ax.legend()\n",
    "\n",
    "# 막대 위에 값 표시\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "\n",
    "# 레이아웃 조정\n",
    "fig.tight_layout()\n",
    "\n",
    "# 그래프 표시\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
